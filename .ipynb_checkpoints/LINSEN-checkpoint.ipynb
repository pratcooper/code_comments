{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexical_analysis import LINSENnormalizer\n",
    "from lexical_analysis import LexicalAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = {'comment':'Returns the change of a user\\'s beverage purchase, or the user\\'s money if the beverage cannot be made',\n",
    "          'code_fragment': \"\"\"public synchronized int makeCoffee(int recipeToPurchase, int amtPaid) {\n",
    "    int change = 0;\n",
    "    if (getRecipes()[recipeToPurchase] == null) {\n",
    "      change = amtPaid;\n",
    "    } else if (getRecipes()[recipeToPurchase].getPrice() <= amtPaid) {\n",
    "      if (inventory.useIngredients(getRecipes()[recipeToPurchase])) {\n",
    "        change = amtPaid - getRecipes()[recipeToPurchase].getPrice();\n",
    "      } else {\n",
    "        change = amtPaid;\n",
    "      }\n",
    "    } else {\n",
    "      change = amtPaid;\n",
    "    }\n",
    "    return change;\"\"\",\n",
    "          'method_name': 'makeCoffee',\n",
    "          'project':'CoffeeMaker',\n",
    "          'src_folder': 'media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer = LexicalAnalyzer(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Analyze words in Comment\n",
      "Comment None English Identifiers\n",
      "\n",
      "Step 2: Analyze words in Source Code\n",
      "Code None English Identifiers\n",
      "int,makeCoffee,int,recipeToPurchase,int,amtPaid,int,0,getRecipes,recipeToPurchase,amtPaid,getRecipes,recipeToPurchase,getPrice,amtPaid,useIngredients,getRecipes,recipeToPurchase,amtPaid,getRecipes,recipeToPurchase,getPrice,amtPaid,amtPaid\n",
      "Step3: Remove Duplicates\n",
      "Target_idenfiers:  {'useIngredients', 'getPrice', 'amtPaid', 'makeCoffee', 'int', '0', 'getRecipes', 'recipeToPurchase'}\n",
      "Step4: LINSEN Normalizer\n",
      "------------------------------------------------------------\n",
      "Test data conf content:  root_project=media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/target_sourcefiles/\n",
      "output_test_set=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/TestLinsen/TestSetDictionary/\n",
      "path_token_file_test_set=\n",
      "path_stopwords_test_set=\n",
      "acronyms_file=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/Acronyms.txt\n",
      "abbreviations_file=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/Abbreviations.txt\n",
      "root_report=media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/LINSEN_report_files/\n",
      "oracle_path=\n",
      "extension_indexing_file=java\n",
      "target_file_path=media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/target_sourcefiles/makecoffee.java\n",
      "target_identifiers_list=media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/target_identifiers.txt\n",
      "------------------------------------------------------------\n",
      "Test Conf file path:  /Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/Linsen/ConfigurationTestSet.properties\n",
      "------------------------------------------------------------\n",
      "Linsen_data_conf_content output_dictionary=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/Structure/COFFEEMAKER/Dictionary/\n",
      "path_token_file_dictionary=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/Informatics.txt;/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/English.txt\n",
      "root_project_dictionary=media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker\n",
      "acronyms_file=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/Acronyms.txt\n",
      "abbreviations_file=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/Abbreviations.txt\n",
      "extension_indexing_file=java\n",
      "path_stopwords_dictionary=/Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/ConfigurationFiles/StopWord.txt\n",
      "------------------------------------------------------------\n",
      "Test Conf file path:  /Users/Kamonphop/Desktop/Research_Phd/DR/code-coherence-analysis/linsen/Linsen/ConfigurationDictionaryforSimilarSplit.properties\n",
      "------------------------------------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "b'Exception in thread \"main\" indexing.index.exceptions.IndexException: Document does not exist\\n\\tat indexing.index.IndexLucene.getDocId(IndexLucene.java:780)\\n\\tat indexing.index.IndexLucene.getTokenDocument(IndexLucene.java:866)\\n\\tat indexing.index.IndexLucene.getExternalDictionary(IndexLucene.java:469)\\n\\tat indexing.index.IndexFactory.createIndex(IndexFactory.java:82)\\n\\tat splitting.SplitTokenModuleFactory.getDictionaryforPatternMatching(SplitTokenModuleFactory.java:149)\\n\\tat splitting.SplitTokenModuleFactory.createSplitModule(SplitTokenModuleFactory.java:94)\\n\\tat splitting.SplitTokenModuleFactory.createSplitModule(SplitTokenModuleFactory.java:100)\\n\\tat splitting.SplitTokenModuleFactory.createPatternMatchingSplittingModule(SplitTokenModuleFactory.java:166)\\n\\tat NormalizeMain.main(NormalizeMain.java:83)\\n'\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/LINSEN_report_files/makecoffee.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8390ed193c69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyse_textual_information\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Research_Phd/DR/code-coherence-analysis/lexical_analysis.py\u001b[0m in \u001b[0;36manalyse_textual_information\u001b[0;34m(self, save_results, show_log)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;31m# Step 3: Identifier Normalization (LINSEN)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;31m# -----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mcode_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_normalize_identifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mcode_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research_Phd/DR/code-coherence-analysis/lexical_analysis.py\u001b[0m in \u001b[0;36m_normalize_identifiers\u001b[0;34m(self, words_in_code, words_in_comment, log)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step4: LINSEN Normalizer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mnormalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLINSENnormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_code_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_identifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mnormalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0;31m# norm_map = normalizer.normalization_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research_Phd/DR/code-coherence-analysis/lexical_analysis.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# -- Fed the `self._normalization_map` attribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_filepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreport_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreport_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# remove last useless comma in line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'media/coffeemaker/1.0/coffeemaker_webzip/extracted/CoffeeMaker_Web/src/edu/ncsu/csc326/coffeemaker/LINSEN_report_files/makecoffee.txt'"
     ]
    }
   ],
   "source": [
    "analyzer.analyse_textual_information()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
